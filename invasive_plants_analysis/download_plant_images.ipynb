{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db983541",
   "metadata": {},
   "source": [
    "https://help.inaturalist.org/en/support/solutions/articles/151000170344"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbd735",
   "metadata": {},
   "source": [
    "This file contains the code used to:\n",
    "\n",
    "- Retrieve the id related to the taxa of the species\n",
    "- Download the images present in iNaturalist for each species\n",
    "\n",
    "through iNaturalist API calls.\n",
    "\n",
    "\n",
    "Note that some of the species taxa were not found in iNaturalist, and were therefore dropped.\n",
    "\n",
    "No results for lythrum americanum\n",
    "\n",
    "No results for lythrum hyrcanicum\n",
    "\n",
    "No results for lythrum lydiae\n",
    "\n",
    "No results for lythrum nieuwlandii\n",
    "\n",
    "No results for lythrum schelkovnikovii\n",
    "\n",
    "No results for lythrum theodori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc9638",
   "metadata": {},
   "source": [
    "### Retrieving iNaturalist ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c54bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170fe354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for session tracking\n",
    "SESSION_LOG_PATH = './support_files/download_session.json'\n",
    "HOURLY_LIMIT = 5 * 1024**3  # 5 GB\n",
    "DAILY_LIMIT = 24 * 1024**3  # 24 GB\n",
    "\n",
    "def load_download_session():\n",
    "    \"\"\"Load or initialize the session data for download tracking.\"\"\"\n",
    "    if not os.path.exists(SESSION_LOG_PATH):\n",
    "        return {\n",
    "            \"hour_start\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"day_start\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"bytes_downloaded_this_hour\": 0,\n",
    "            \"bytes_downloaded_today\": 0\n",
    "        }\n",
    "    with open(SESSION_LOG_PATH, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_download_session(session_data):\n",
    "    \"\"\"Save session data to disk.\"\"\"\n",
    "    folder = os.path.dirname(SESSION_LOG_PATH)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    with open(SESSION_LOG_PATH, 'w') as f:\n",
    "        json.dump(session_data, f)\n",
    "\n",
    "def check_and_reset_limits(session):\n",
    "    \"\"\"Reset hourly or daily byte counters if time has rolled over.\"\"\"\n",
    "    now = datetime.now(timezone.utc)\n",
    "    hour_start = datetime.fromisoformat(session[\"hour_start\"])\n",
    "    if now - hour_start >= timedelta(hours=1):\n",
    "        session[\"hour_start\"] = now.isoformat()\n",
    "        session[\"bytes_downloaded_this_hour\"] = 0\n",
    "    day_start = datetime.fromisoformat(session[\"day_start\"])\n",
    "    if now - day_start >= timedelta(days=1):\n",
    "        session[\"day_start\"] = now.isoformat()\n",
    "        session[\"bytes_downloaded_today\"] = 0\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538a43e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEPTED_LICENSES = {'cc0', 'cc-by', 'cc-by-nc', 'cc-by-sa', 'cc-by-nc-sa', 'cc-by-nd', 'cc-by-nc-nd'}\n",
    "\n",
    "#global daily API counter (no more than 10000)\n",
    "api_call_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549827e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where the species list with the correct name format is saved. It is the same as the file 'plant_zones_extraction'\n",
    "species_list_path = 'support_files/invasive_plants_name_list.csv'\n",
    "\n",
    "species_id_path = 'support_files/species_inaturalist_ids.csv'\n",
    "\n",
    "#keep track of downloaded url\n",
    "DOWNLOAD_LOG_PATH = './support_files/downloaded_photos.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de0359",
   "metadata": {},
   "source": [
    "### Retrieving the IDs from the taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53aa8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxon_id(scientific_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Given a scientific name (e.g. 'lythrum salicaria') return the corresponding iNaturalist id.\n",
    "    \"\"\"\n",
    "\n",
    "    global api_call_count\n",
    "\n",
    "    url = \"https://api.inaturalist.org/v1/taxa\"\n",
    "    params = {'q' : scientific_name}\n",
    "    #user agent is not necessary but recommended, to be able to be contacted by iNaturalist if needed\n",
    "    headers = {'User-Agent' : 'InatImageDownloader/1.0 (s319848@studenti.polito.it)'}\n",
    "\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching taxon for {scientific_name}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    #example of response body:\n",
    "\n",
    "#     {\n",
    "#   \"total_results\": 1,\n",
    "#   \"page\": 1,\n",
    "#   \"per_page\": 30,\n",
    "#   \"results\": [\n",
    "#     {\n",
    "#       \"id\": 61321,\n",
    "#       \"rank\": \"species\",\n",
    "#       \"rank_level\": 10,\n",
    "#       \"iconic_taxon_id\": 47126,\n",
    "#       \"ancestor_ids\": [\n",
    "#         48460,\n",
    "#         47126,\n",
    "#         211194,\n",
    "#         47125,\n",
    "#         47124,\n",
    "#         47791,\n",
    "#         58935,\n",
    "#         58937,\n",
    "#         61321\n",
    "#       ],\n",
    "#       \"is_active\": true,\n",
    "#       \"name\": \"Lythrum salicaria\",\n",
    "#       \"parent_id\": 58937,\n",
    "#       \"ancestry\": \"48460/47126/211194/47125/47124/47791/58935/58937\",\n",
    "#       \"extinct\": false,\n",
    "#       \"default_photo\": {\n",
    "#         \"id\": 63744014,\n",
    "#         \"license_code\": null,\n",
    "#         \"attribution\": \"(c) wojtest, all rights reserved, uploaded by wojtest\",\n",
    "#         \"url\": \"https://static.inaturalist.org/photos/63744014/square.jpeg\",\n",
    "#         \"original_dimensions\": {\n",
    "#           \"height\": 2048,\n",
    "#           \"width\": 1362\n",
    "#         },\n",
    "#         \"flags\": [],\n",
    "#         \"attribution_name\": \"wojtest\",\n",
    "#         \"square_url\": \"https://static.inaturalist.org/photos/63744014/square.jpeg\",\n",
    "#         \"medium_url\": \"https://static.inaturalist.org/photos/63744014/medium.jpeg\"\n",
    "#       },\n",
    "#       \"taxon_changes_count\": 1,\n",
    "#       \"taxon_schemes_count\": 6,\n",
    "#       \"observations_count\": 99403,\n",
    "#       \"flag_counts\": {\n",
    "#         \"resolved\": 2,\n",
    "#         \"unresolved\": 0\n",
    "#       },\n",
    "#       \"current_synonymous_taxon_ids\": null,\n",
    "#       \"atlas_id\": null,\n",
    "#       \"complete_species_count\": null,\n",
    "#       \"wikipedia_url\": \"http://en.wikipedia.org/wiki/Lythrum_salicaria\",\n",
    "#       \"matched_term\": \"Lythrum salicaria\",\n",
    "#       \"iconic_taxon_name\": \"Plantae\",\n",
    "#       \"preferred_common_name\": \"purple loosestrife\"\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "    api_call_count += 1\n",
    "\n",
    "    results = data.get('results', []) #if results key is absent, return an empty list\n",
    "\n",
    "    if results:\n",
    "        taxon_info = results[0]\n",
    "        return int(taxon_info['id'])\n",
    "    else:\n",
    "        print(f\"No results for {scientific_name}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef6e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_species_ids(species_list_path, species_id_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a file containing the list of species, retrieve the iNaturalist id for each taxon.\n",
    "    Return a dataframe containing the species taxon and the corresponding iNaturalist id.\n",
    "    \"\"\"\n",
    "\n",
    "    #dataframe containing the list of species. In this case, it also contains other info that we are not going to use in this use case (retrieving pictures)\n",
    "    species_list = pd.read_csv(species_list_path)\n",
    "\n",
    "    species_list_list = species_list['Species'].to_list()\n",
    "\n",
    "    #call the function that retrieves the single id\n",
    "    species_ids_list = [get_taxon_id(taxon) for taxon in species_list_list]\n",
    "\n",
    "    species_list['inat_id'] = species_ids_list\n",
    "\n",
    "    species_list = species_list.dropna(subset=['inat_id'])\n",
    "    species_list['inat_id'] = species_list['inat_id'].astype(int)\n",
    "\n",
    "    #save the new dataframe in a csv\n",
    "    species_list.to_csv(species_id_path, index=False)\n",
    "\n",
    "    return species_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9652da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# species_id = retrieve_species_ids(species_list_path, species_id_path)\n",
    "\n",
    "# species_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1706f64",
   "metadata": {},
   "source": [
    "### Downloading pictures and metadata for each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03198cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_photo_metadata(taxon_id, max_api_calls=10000) -> List[Dict]:\n",
    "    \"\"\"Retrieve photo metadata for all observations of a taxon.\n",
    "        Metadata include \n",
    "            - url\n",
    "            - license code\n",
    "            - observation id\n",
    "            - quality grade\n",
    "            - coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    global api_call_count\n",
    "    photo_metadata = []\n",
    "    page = 1\n",
    "    per_page = 200\n",
    "    headers = {'User-Agent' : 'InatImageDownloader/1.0 (s319848@studenti.polito.it)'}\n",
    "\n",
    "\n",
    "    while True:\n",
    "        if api_call_count >= max_api_calls:\n",
    "            print(\"Reached daily API limits\")\n",
    "            break\n",
    "\n",
    "        url = 'https://api.inaturalist.org/v1/observations'\n",
    "\n",
    "        params = {\n",
    "            'taxon_id' : taxon_id,\n",
    "            'photos' : 'true',\n",
    "            'page' : page,\n",
    "            'per_page' : per_page,\n",
    "            'order_by' : 'created_at'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        api_call_count +=1\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error at page {page}, (HTTP {response.status_code})\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        results = data.get('results', [])\n",
    "\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "\n",
    "        for obs in tqdm(results, desc=f'Page {page}', leave=False):\n",
    "\n",
    "            obs_id = obs['id']\n",
    "            quality = obs.get('quality_grade')\n",
    "            geo = obs.get('geojson') or {}\n",
    "            coords = geo.get('coordinates', [None, None])\n",
    "            lon, lat = coords\n",
    "\n",
    "\n",
    "            for photo in obs.get('photos', []):\n",
    "\n",
    "                if not photo:\n",
    "                    continue\n",
    "\n",
    "                license_code = photo.get('license_code', '')\n",
    "                if not license_code:\n",
    "                    continue\n",
    "                license_code.lower()\n",
    "                \n",
    "                if license_code not in ACCEPTED_LICENSES:\n",
    "                    continue\n",
    "                    #if the photo has 'all rights reserved' copyright, skip it\n",
    "\n",
    "                #You can change from \"medium\" it to \"original\" to increase quality, but this is useful to reduce the stress on the servers\n",
    "                full_url = photo['url'].replace('square', 'medium')\n",
    "\n",
    "                photo_metadata.append(\n",
    "                    {\n",
    "                        'url': full_url,\n",
    "                        'license_code': license_code,\n",
    "                        'observation_id': obs_id,\n",
    "                        'quality_grade': quality,\n",
    "                        'latitude': lat,\n",
    "                        'longitude': lon\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    print(f'Retrieved {len(photo_metadata)} photo entries using {api_call_count} API calls')\n",
    "\n",
    "    return photo_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3147631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_downloaded_url(url, file_path=DOWNLOAD_LOG_PATH):\n",
    "    \"\"\"Write every photo url in a new line\"\"\"\n",
    "\n",
    "    folder = os.path.dirname(file_path)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        \n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(url + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9564b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_downloaded_urls(file_path=DOWNLOAD_LOG_PATH) -> set:\n",
    "    \"\"\"From the file with the urls, return a set (unique urls) with the urls to work with\"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        return set(line.strip() for line in f if line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025d4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_photos(photo_metadata: List[Dict], species_name: str, downloaded_urls: set, download_log=DOWNLOAD_LOG_PATH):\n",
    "    \"\"\"This function downloads photos related to a given species, keeping track of the downloaded\n",
    "    URLs to avoid downloading them twice and being able to resume the downloading if interrupted.\n",
    "    \n",
    "    Parameters:\n",
    "        - photo_metadata: list of image metadata from iNaturalist, including URL\n",
    "        - species_name: list of scientific names of the species\n",
    "        - downloaded_urls: set of already downloaded urls to avoid downloading them twice\n",
    "        - download_log: the file to save the newly downloaded photo URLs\n",
    "    \"\"\"\n",
    "\n",
    "    species_dir = os.path.join('support_files', 'photos', species_name.replace(' ', '_'))\n",
    "\n",
    "    if not os.path.exists(species_dir):\n",
    "        os.makedirs(species_dir) #create folder if it doesn't exist yet\n",
    "\n",
    "    downloaded_count = 0 #keep track of how many images we have downloaded in this session\n",
    "\n",
    "    #load a json file that remembers when the last download session started and how many bytes \n",
    "    #have been downnloaded so far this hour and this day\n",
    "    session = load_download_session()\n",
    "\n",
    "    #check if hour/day has passed and eventually reset\n",
    "    session = check_and_reset_limits(session)\n",
    "\n",
    "    for i, photo in tqdm(enumerate(photo_metadata), total=len(photo_metadata), desc=f'{species_name}'):\n",
    "\n",
    "        url = photo['url'] #retrieve the URL from the metadata\n",
    "\n",
    "        if url in downloaded_urls:\n",
    "            continue #skip this image if it is present in downloaded_urls (already been downloaded)\n",
    "\n",
    "        try: \n",
    "            #send a GET request to the image URL (not the actual API call for the image)\n",
    "            response = requests.get(url)\n",
    "\n",
    "            #check if the server returned a successful response\n",
    "            if response.status_code == 200:\n",
    "\n",
    "                image_data = response.content\n",
    "                image_size = len(image_data)\n",
    "\n",
    "                # Check byte limits\n",
    "                if session[\"bytes_downloaded_this_hour\"] + image_size > HOURLY_LIMIT:\n",
    "                    print(\"Hourly limit reached (5GB). Halting downloads.\")\n",
    "                    break\n",
    "                if session[\"bytes_downloaded_today\"] + image_size > DAILY_LIMIT:\n",
    "                    print(\"Daily limit reached (24GB). Halting downloads.\")\n",
    "                    break\n",
    "\n",
    "                #get the file extension (jpg, png) by splitting the URL at the dots\n",
    "                ext = url.split('.')[-1].split('?')[0] #handles URLs  with ?query=string\n",
    "\n",
    "                #create a file_name like \"lythrum_salicaria_1.jpg\"\n",
    "                filename = f\"{species_name.replace(' ', '_')}_{i+1:03}.{ext}\"\n",
    "                filepath = os.path.join(species_dir, filename)\n",
    "\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "                # Add the filename to the metadata dictionary - Apparently we are passing it by reference, so it is modifyied everywhere\n",
    "                photo['filename'] = filename\n",
    "\n",
    "                #log this URL to the file so we don't re-download it later\n",
    "                save_downloaded_url(url, download_log)\n",
    "\n",
    "                # Update counters\n",
    "                session[\"bytes_downloaded_this_hour\"] += image_size\n",
    "                session[\"bytes_downloaded_today\"] += image_size\n",
    "\n",
    "                downloaded_count += 1\n",
    "\n",
    "            else:\n",
    "                print(f'Failed to download {url} (HTTP {response.status_code})')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error downloading {url}: {e}')\n",
    "\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    save_download_session(session)\n",
    "    print(f'{downloaded_count} new images downloaded for {species_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df64bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata_csv(metadata_list: List[Dict], filename: str):\n",
    "    \"\"\"Save the picture metadata in a csv file\"\"\"\n",
    "\n",
    "    folder = os.path.dirname(filename)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    keys = ['filename', 'url', 'license_code', 'observation_id', 'quality_grade', 'latitude', 'longitude']\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7c962",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11257871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing species lythrum acutangulum (ID: 1562194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 24 photo entries using 4 API calls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lythrum acutangulum: 100%|██████████| 24/24 [00:00<00:00, 24076.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new images downloaded for lythrum acutangulum\n",
      "Processing species lythrum alatum (ID: 128998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m taxon_id = row[\u001b[33m'\u001b[39m\u001b[33minat_id\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mProcessing species \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtaxon_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m photo_metadata = \u001b[43mget_all_photo_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaxon_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m downloaded_urls = load_downloaded_urls()\n\u001b[32m     26\u001b[39m download_photos(photo_metadata, species, downloaded_urls)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mget_all_photo_metadata\u001b[39m\u001b[34m(taxon_id, max_api_calls)\u001b[39m\n\u001b[32m     23\u001b[39m url = \u001b[33m'\u001b[39m\u001b[33mhttps://api.inaturalist.org/v1/observations\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     25\u001b[39m params = {\n\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtaxon_id\u001b[39m\u001b[33m'\u001b[39m : taxon_id,\n\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mphotos\u001b[39m\u001b[33m'\u001b[39m : \u001b[33m'\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33morder_by\u001b[39m\u001b[33m'\u001b[39m : \u001b[33m'\u001b[39m\u001b[33mcreated_at\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     31\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     37\u001b[39m api_call_count +=\u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guido\\Desktop\\Politecnico\\Thesis\\Code\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\http\\client.py:1423\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1425\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python312\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "### MAIN FILE ###\n",
    "\n",
    "if os.path.isfile(species_id_path):\n",
    "    species_id_df = pd.read_csv(species_id_path)\n",
    "else:\n",
    "    species_id_df = retrieve_species_ids(species_list_path, species_id_path)\n",
    "\n",
    "downloaded_urls = load_downloaded_urls()\n",
    "\n",
    "\n",
    "#THIS ONLY KEEPS THE FIRST SPECIES, LYTHRUM ACUTANGULUM, WHICH HAS 24 PICTURES, GREAT FOR TESTING.\n",
    "# test_df = species_id_df.head(1)\n",
    "\n",
    "#UNCOMMENT THE FIRST LINE AND COMMENT THE SECOND TO USE THE WHOLE DATAFRAME INSTEAD OF ONLY ONE SPECIES\n",
    "for index, row in species_id_df.iterrows():\n",
    "# for index, row in test_df.iterrows():\n",
    "    species = row['Species']\n",
    "    taxon_id = row['inat_id']\n",
    "\n",
    "    print(f'Processing species {species} (ID: {taxon_id})')\n",
    "\n",
    "    photo_metadata = get_all_photo_metadata(taxon_id)\n",
    "\n",
    "    downloaded_urls = load_downloaded_urls()\n",
    "\n",
    "    download_photos(photo_metadata, species, downloaded_urls)\n",
    "\n",
    "    save_metadata_csv(photo_metadata, f\"./support_files/metadata/{species.replace(' ', '_')}_metadata.csv\")\n",
    "    downloaded_urls.update([photo['url'] for photo in photo_metadata])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
